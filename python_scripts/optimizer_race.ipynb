{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df4325ff-71ae-46f4-aacc-a3107fb0c083",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Race to low rms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2945fbc-d119-407f-88e5-47731e7318fc",
   "metadata": {},
   "source": [
    "Import latin-hypercube test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0d5cdc-cd9e-4e66-b4e2-c70a66e3af71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import netcdf_read_write as nrw\n",
    "import training_data_generation as tdg\n",
    "import utils_optimizers as uopt\n",
    "import optimize as opt\n",
    "import healpy as hp\n",
    "import utils_intensity_map as uim\n",
    "import utils_healpy as uhp\n",
    "import utils_deck_generation as idg\n",
    "%matplotlib inline\n",
    "plt.ion()\n",
    "np_complex = np.vectorize(complex)\n",
    "run_dir = \"Data\"\n",
    "num_modes = 30\n",
    "num_inputs = 16\n",
    "random_seed = 12345\n",
    "display_steradians = False\n",
    "\n",
    "sys_params = tdg.define_system_params(run_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d9d5b9-619b-4c93-ac41-fbf22450ce53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset, dataset_params, deck_gen_params, facility_spec = idg.load_data_dicts_from_file(sys_params)\n",
    "\n",
    "opt_params = uopt.define_optimizer_parameters(run_dir, 0, 0, dataset_params, facility_spec, sys_params)\n",
    "print(np.shape(dataset[\"rms\"]))\n",
    "num_sims = np.shape(dataset[\"rms\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e92d1ff-e640-41d4-831a-8c27e201be57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_evaluated = dataset[\"num_evaluated\"]\n",
    "total_outputs = np.shape(dataset[\"rms\"])[0]*np.shape(dataset[\"rms\"])[1]\n",
    "num_zero_vals = np.count_nonzero(dataset[\"rms\"]==0)\n",
    "ind = np.where(dataset[\"rms\"]==0)\n",
    "\n",
    "num_failed = (2 * num_evaluated) - (total_outputs - num_zero_vals)\n",
    "print(\"Number of failed outputs in the dataset (2 per config): \", num_failed)\n",
    "print(ind[0])\n",
    "\n",
    "ind_bug = np.where(dataset[\"avg_flux\"][:,1] > 100.0)\n",
    "num_failed = len(ind_bug[0])\n",
    "print(\"Number of bugs occured in intensity/drive output (caused by CBET convergence): \", num_failed)\n",
    "print(ind_bug[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b0cb54-a7bc-4bc4-910b-87c46246ae44",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Evaluate distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8195a037-22af-4c57-8f32-7edb68e54952",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ind_profile = 0\n",
    "\n",
    "inputs_mean = np.mean(dataset[\"input_parameters\"])\n",
    "input_standard_deviation = np.sqrt(np.var(dataset[\"input_parameters\"], axis=0))\n",
    "#print(inputs_mean, input_standard_deviation)\n",
    "fitness = uopt.fitness_function(dataset, opt_params)\n",
    "number_of_timesteps = np.shape(dataset[\"rms\"][:,:])[1]\n",
    "rms_of_rms = np.sqrt(np.sum(dataset[\"rms\"][:,:]**2, axis=1) / float(number_of_timesteps))\n",
    "\n",
    "argmin_rms = np.argmin(dataset[\"rms\"][:,ind_profile])\n",
    "print(argmin_rms, fitness[argmin_rms], rms_of_rms[argmin_rms], dataset[\"avg_flux\"][argmin_rms, ind_profile])\n",
    "rms_mean = np.mean(dataset[\"rms\"][:,ind_profile])\n",
    "rms_standard_deviation = np.sqrt(np.var(dataset[\"rms\"][:,ind_profile]))\n",
    "print(rms_mean*100.0, rms_standard_deviation*100.0)\n",
    "\n",
    "argmax_fitness = np.argmax(fitness[:])\n",
    "print(\"Max fitness: \", argmax_fitness, fitness[argmax_fitness], rms_of_rms[argmax_fitness], dataset[\"avg_flux\"][argmax_fitness, ind_profile])\n",
    "\n",
    "argmax_drive = np.argmax(dataset[\"avg_flux\"][:,ind_profile])\n",
    "print(\"Max drive: \", argmax_drive, fitness[argmax_drive], rms_of_rms[argmax_drive], dataset[\"avg_flux\"][argmax_drive, ind_profile])\n",
    "\n",
    "argmin_rms = np.argmin(rms_of_rms)\n",
    "print(\"Min RMS: \", argmin_rms, fitness[argmin_rms], rms_of_rms[argmin_rms], dataset[\"avg_flux\"][argmin_rms, ind_profile])\n",
    "\n",
    "argmin_rms0 = np.argmin(dataset[\"rms\"][:,0])\n",
    "print(\"Min RMS0: \", argmin_rms0, fitness[argmin_rms0], rms_of_rms[argmin_rms0], dataset[\"avg_flux\"][argmin_rms0, ind_profile])\n",
    "\n",
    "num_of_max = 3\n",
    "ind = np.argpartition(fitness[:], -num_of_max)[-num_of_max:]\n",
    "print(\"Max 3 fitnesses: \", ind)\n",
    "print(fitness[ind])\n",
    "print(dataset[\"rms\"][ind, ind_profile])\n",
    "print(dataset[\"avg_flux\"][ind, ind_profile])\n",
    "rms_of_rms = np.sqrt((dataset[\"rms\"][:,0]**2+dataset[\"rms\"][:,1]**2)/2.0)\n",
    "\n",
    "arg_norm = argmax_fitness\n",
    "start_ind = 0\n",
    "x_markers = np.linspace(start_ind, num_sims, num_sims-start_ind)\n",
    "plt.plot(x_markers,fitness[start_ind:]/fitness[arg_norm], label=\"fitness\")\n",
    "plt.plot(x_markers,rms_of_rms[start_ind:]/rms_of_rms[arg_norm], label=\"rms\")\n",
    "plt.plot(x_markers,(dataset[\"avg_flux\"][start_ind:,ind_profile]/dataset[\"avg_flux\"][arg_norm,ind_profile])**6, label=\"ablation pressure\")\n",
    "plt.legend()\n",
    "\n",
    "fitness_mean = np.mean(fitness)\n",
    "fitness_standard_deviation = np.sqrt(np.var(fitness))\n",
    "print(fitness_mean, fitness_standard_deviation, np.max(fitness), np.min(fitness))\n",
    "argmin_fitness = np.argmin(fitness[:])\n",
    "print(argmin_fitness, dataset[\"rms\"][argmin_fitness,ind_profile], dataset[\"avg_flux\"][argmin_fitness,ind_profile])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed822acc-fbad-4be8-80f4-9eaa46e9549c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arg_plot = argmax_fitness\n",
    "\n",
    "#print(dataset[\"input_parameters\"][arg_plot,:])\n",
    "#print(deck_gen_params[\"sim_params\"][arg_plot,:])\n",
    "\n",
    "avg_flux = dataset[\"avg_flux\"][arg_plot, ind_profile]\n",
    "real_modes = dataset[\"real_modes\"][arg_plot,ind_profile,:]\n",
    "imag_modes = dataset[\"imag_modes\"][arg_plot,ind_profile,:]\n",
    "rms = dataset[\"rms\"][arg_plot, ind_profile]\n",
    "\n",
    "intensity_map_normalized = uhp.modes2imap(real_modes, imag_modes, dataset_params[\"imap_nside\"])\n",
    "intensity_map_sr = (intensity_map_normalized+1)*avg_flux\n",
    "\n",
    "#print('Mean intensity per steradian, {:.2e}W/sr'.format(avg_flux))\n",
    "print(\"Initial rms : \", dataset[\"rms\"][arg_plot, 0]*100.0, \"%\")\n",
    "print(\"Ablation pressure rms: \", dataset[\"rms\"][arg_plot, 1]*100.0, \"%\")\n",
    "\n",
    "if ind_profile == 0:\n",
    "    print('Mean intensity per steradian, {:.2e}W/sr'.format(avg_flux))\n",
    "    print('Power deposited {:.2f}TW, '.format(avg_flux * 4.0 * np.pi / 1.0e12))\n",
    "    #print('Power emitted {:.2f}TW, '.format(facility_spec['default_power'] * facility_spec['nbeams']))\n",
    "    if display_steradians:\n",
    "        drive_map = intensity_map_sr\n",
    "        drive_units = r\"$\\rm{W/sr}$\"\n",
    "    else:\n",
    "        drive_map = (intensity_map_normalized+1)*avg_flux / (facility_spec['target_radius'] / 10000.0)**2\n",
    "        drive_units = r\"$\\rm{W/cm^2}$\"\n",
    "else:\n",
    "    drive_map = intensity_map_sr\n",
    "    drive_units = r\"$\\rm{Mbar}$\"\n",
    "    print('Mean ablation pressure: {:.2f}Mbar, '.format(avg_flux))\n",
    "\n",
    "intensity_map_normalized = uhp.modes2imap(real_modes, imag_modes, dataset_params[\"imap_nside\"])\n",
    "intensity_map_sr = (intensity_map_normalized+1)*avg_flux\n",
    "\n",
    "hp.mollview(drive_map, unit=drive_units,flip=\"geo\")\n",
    "hp.graticule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d19431f-c036-4c6f-8dfe-ec0cf8fa24c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "complex_modes = np_complex(real_modes, imag_modes)\n",
    "power_spectrum = uhp.alms2power_spectrum(complex_modes, dataset_params[\"LMAX\"])\n",
    "print(\"The rms is: \", np.sqrt(np.sum(power_spectrum))*100.0, \"%\")\n",
    "\n",
    "LMAX = dataset_params[\"LMAX\"]\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "plt.plot(np.arange(LMAX), np.sqrt(power_spectrum) * 100.0)\n",
    "ax.set_xticks(range(0, LMAX+1, int(LMAX/5)))\n",
    "plt.xlim([0, LMAX])\n",
    "plt.title(\"Modes\")\n",
    "plt.xlabel(\"l mode\")\n",
    "plt.ylabel(r\"amplitude ($\\%$)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d030fdb1-4c00-47a3-9b81-fdcea09adfba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Compare Optimization Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34e6c89-b621-4001-8f53-86a7442c778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs_for_comparison = [\"Data\",\n",
    "                       \"Data2\"]\n",
    "optimization_label = [\"Data label\",\n",
    "                      \"Data2 label\"]\n",
    "colours = mcolors.TABLEAU_COLORS\n",
    "colour_keys = list(colours.keys())\n",
    "\n",
    "ind_cutoff = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef96b3f-9258-49c3-91f4-4fc0e195a81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure(figsize=(6, 6), dpi=80)\n",
    "ax1 = plt.axes()\n",
    "\n",
    "fig2 = plt.figure(figsize=(6, 6), dpi=80)\n",
    "ax2 = plt.axes()\n",
    "\n",
    "data_set = 0\n",
    "for run_dir in dirs_for_comparison:\n",
    "    sys_params = tdg.define_system_params(run_dir)\n",
    "    \n",
    "    dataset = nrw.read_general_netcdf(sys_params[\"data_dir\"] + \"/\" + sys_params[\"trainingdata_filename\"])\n",
    "    fitness = uopt.fitness_function(dataset, opt_params)\n",
    "\n",
    "    window_size = 100\n",
    "  \n",
    "    i = 0\n",
    "    # Initialize an empty list to store moving averages\n",
    "    moving_min_rms = []\n",
    "    moving_max_fitness = []\n",
    "  \n",
    "    # Loop through the array to consider every window of size 3\n",
    "    while i < len(fitness) - window_size + 1:\n",
    "        # taken from https://www.geeksforgeeks.org/how-to-calculate-moving-averages-in-python/\n",
    "\n",
    "        window_min = np.min(dataset[\"rms\"][i:i+window_size,ind_profile])\n",
    "        moving_min_rms.append(window_min)\n",
    "\n",
    "        window_max = np.max(fitness[i:i+window_size])\n",
    "        moving_max_fitness.append(window_max)\n",
    "\n",
    "        # Shift window to right by one position\n",
    "        i += 1\n",
    "    moving_min = np.array(moving_min_rms)\n",
    "    moving_max = np.array(moving_max_fitness)\n",
    "    \n",
    "    num_examples = len(moving_min)\n",
    "    array_examples = np.linspace(1,num_examples, num=num_examples).astype(int)\n",
    "\n",
    "    ax1.semilogy(array_examples[:ind_cutoff], moving_min[:ind_cutoff] * 100.0, linestyle=\"solid\", color=colours[colour_keys[data_set]], label=optimization_label[data_set])\n",
    "    ax2.plot(array_examples[:ind_cutoff], moving_max[:ind_cutoff], linestyle=\"solid\", color=colours[colour_keys[data_set]], label=optimization_label[data_set]),\n",
    "    data_set += 1\n",
    "ax1.legend();\n",
    "ax1.set_ylim(0.9, 30)\n",
    "ax1.set_xlabel(\"Number of simulations\")\n",
    "ax1.set_ylabel(r\"Minimum RMS for moving window size: \" + str(window_size) + r\" ($\\%$)\");\n",
    "fig1.savefig(\"Compare_optimization_techniques_rms\" + sys_params[\"plot_file_type\"], dpi=300, bbox_inches='tight')\n",
    "ax2.legend();\n",
    "ax2.set_xlabel(\"Number of simulations\")\n",
    "ax2.set_ylabel(r\"Fitness function for moving window size: \" + str(window_size))\n",
    "fig2.savefig(\"Compare_optimization_techniques_fitness\" + sys_params[\"plot_file_type\"], dpi=300, bbox_inches='tight');\n",
    "#fig2.savefig(\"Compare_optimization_techniques\" + sys_params[\"plot_file_type\"], dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ff8ef3-69fb-42b2-b223-f827dd5d65b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Method 1, Brute force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1ab928-25b7-40d7-9491-4fc4e821de9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e8c427-27ad-4e0e-bd90-70d47385ab61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b01aa36-7861-4579-8661-aef3dcba1048",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Method 2, Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c2f2f7-6611-4457-b6b0-ce4ca6f64853",
   "metadata": {},
   "source": [
    "The partial derivative is determined using a 2*16=32 grid of points (2 points in every dimension) around the current minima. These points can be evaluated in either a NN or Ifriit depending on speed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79da5299-4665-4ceb-8b66-4b793d3bb257",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Method 3, Use surrogate NN to pick low RMS from random inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031dec62-d5d3-45c8-9e12-994cacd16898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6aee649-2a79-42ac-bce4-3c08a13163e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Method 4, Use inverse NN to indentify low rms by inputing other low rms cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142e4f0e-8662-4785-b271-26bf3d8c0b98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd77d77f-e069-4822-92d9-72e0dd89cf39",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Method 5, Genetic algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7b6d4c-1890-4664-9dc9-1e6a1d92ceb1",
   "metadata": {},
   "source": [
    "Iterative procedure taking best features of first generation. Mutate and mix inputs between the best and produce subsequent generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ba0f5b-722d-41ec-889e-3f41d91091c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Method 6, Bayesian optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9609d4-311e-4ee7-a61e-7b4e38c3bd77",
   "metadata": {},
   "source": [
    "Gaussian process surrogate and bayesian optimization used with multiple sources of information. First we create a bayesian model with the true data points and select new simulations based on that. The model (Kriging method?) could use a \"gaussian process approximation\" to reduce computational expense.\n",
    "\n",
    "Future extension: multi-source bayesian optimization, (ifriit is high quality source and NN is low quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3dba49-4564-4a4e-8dda-cb8fa35e88db",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Method 7, Grid search algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0393c6d1-d0e5-4743-a7e6-a1bc95c26184",
   "metadata": {},
   "source": [
    "Split the entire search space into a grid (start coarse 2 or 3 cells per dimension) 3^16 = 43M. Evaluate each cell depending on the data points within or 8 nearest neighbours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4101477-d30f-460f-9e81-f25e7d235136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f025763f-d7b4-498b-a1c4-ba2848fff404",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Method 8, Network search algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b292c18-5aa8-41c0-b3bb-f7a4ed751694",
   "metadata": {},
   "source": [
    "Find a gradient between all data points, use this information to initialize gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37784580-9e53-4183-ad8e-41bf06a96e45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df5e1428-8dcf-479d-a30b-2fca0f4db9f0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Method 9, Principle Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3eb066-8f05-4af0-ad97-28b1fed1a6d0",
   "metadata": {},
   "source": [
    "Combine with gradient descent for faster convergence? Enables plotting of dataset in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b25c333-f2c6-40bf-8a8f-83d67f1722a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef247b59-ff08-4800-8a8c-4ef9d557e474",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Method 10, Transfer Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e486b0-da4f-4b91-b8dd-1c055f968a88",
   "metadata": {},
   "source": [
    "Generate low quality large dataset (1-50M examples?) using surrogate NN and use this for transfer learning. This might help to evaluate at what stage transfer learning becomes effective (can we use it with a dataset of 1000 or 10000?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f00d0b3-c62c-4544-9a26-489690fbe104",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
